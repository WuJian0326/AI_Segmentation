2023-01-12 18:26:39,730 [train.py:60] INFO: learning rate : 0.0005
2023-01-12 18:26:39,730 [train.py:61] INFO: batch size : 160
2023-01-12 18:26:39,730 [train.py:62] INFO: num epoch : 100
2023-01-12 18:26:39,731 [train.py:63] INFO: trainflow: 5
2023-01-12 18:26:39,732 [train.py:106] INFO: ==========Start training=========
2023-01-12 18:27:49,718 [trainer.py:188] INFO: Epoch : 1, Train_loss : nan, Mean_ioU: 0.19915407390324505
2023-01-12 18:28:57,486 [trainer.py:188] INFO: Epoch : 2, Train_loss : nan, Mean_ioU: 0.21663833595567364
2023-01-12 18:30:04,019 [trainer.py:188] INFO: Epoch : 3, Train_loss : nan, Mean_ioU: 0.22646996721999774
2023-01-12 18:31:09,351 [trainer.py:188] INFO: Epoch : 4, Train_loss : nan, Mean_ioU: 0.24678300832674893
2023-01-12 18:32:14,205 [trainer.py:188] INFO: Epoch : 5, Train_loss : nan, Mean_ioU: 0.24678300832674893
2023-01-12 18:34:21,094 [trainer.py:220] INFO: Validation: Loss : nan, mIoU : 0.24675560129353535
2023-01-12 18:35:27,156 [trainer.py:188] INFO: Epoch : 6, Train_loss : nan, Mean_ioU: 0.24678300832674893
2023-01-12 18:36:33,403 [trainer.py:188] INFO: Epoch : 7, Train_loss : nan, Mean_ioU: 0.24678300832674893
2023-01-12 18:37:37,593 [trainer.py:188] INFO: Epoch : 8, Train_loss : nan, Mean_ioU: 0.24678300832674893
2023-01-12 18:38:42,938 [trainer.py:188] INFO: Epoch : 9, Train_loss : nan, Mean_ioU: 0.24678300832674893
2023-01-12 18:39:48,025 [trainer.py:188] INFO: Epoch : 10, Train_loss : nan, Mean_ioU: 0.24678300832674893
